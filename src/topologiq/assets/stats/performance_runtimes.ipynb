{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59befabc",
   "metadata": {},
   "source": [
    "# Performance: Runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1deaefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "root_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "stats_dir = os.path.join(root_dir, \"assets/stats\")\n",
    "if root_dir not in sys.path:\n",
    "    sys.path.insert(0, root_dir)\n",
    "    \n",
    "from topologiq.scripts.pathfinder import test_pthfinder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73b7a12",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a368d42",
   "metadata": {},
   "source": [
    "This notebook aims to offer a means to test Topologiq's runtimes. It starts with checks for the pathfinder's single edge construction, then moves into full circuit generation.\n",
    "\n",
    "The expectations are:\n",
    "- Runtimes should increase linearly against the total number of sites visited in any given iteration of the pathfinder algorithm,\n",
    "- Runtimes should increase exponentially against the radius of the space searched in any given iteration of the pathfinder algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da3474f",
   "metadata": {},
   "source": [
    "## 2. Single edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316b748d",
   "metadata": {},
   "source": [
    "Let's start with some tests designed to test the pathfinder's core function by asking it to make paths between all kinds of cubes and all kinds of cubes, with cubes placed at different Manhattan distances from one another.\n",
    "\n",
    "Internally, the function below calls the pathfinder with a unique run identifier via the optional parameter `log_stats_id`. The identifier has a \"*\" at the end to prompt stats are saved to a file specifically for tests as opposed to the file used to tracking stats for generation of paths as part of full circuit operations.\n",
    "\n",
    "*Please note the block below calls the algorithm over 300 times. It will take a while! A few minutes, perhaps.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003437e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_test_step = 9\n",
    "num_repetitions = 10\n",
    "min_succ_rate = 100\n",
    "test_pthfinder(\n",
    "    stats_dir,\n",
    "    min_succ_rate,\n",
    "    max_test_step=max_test_step,\n",
    "    num_repetitions=num_repetitions,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5c23c7",
   "metadata": {},
   "source": [
    "Before visualising the data, we will filter it to control for the following factors:\n",
    "- Ignore failures (the outer graph manager algorithm has ways to deal with individual failures by the pathfinder, but the code above tests only the pathfinder so runtimes of failed runs would bias statistics),\n",
    "- Ignore boundary (\"O\") nodes (the algorithm deals with \"O\" nodes with something of a a shortcut, so their runtimes would bias runtimes statistics),\n",
    "- Ignore runtimes equal to 0 seconds (since the algorithm is fast, the computer's clock will not always clock it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443654f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df_iter = pd.read_csv(os.path.join(stats_dir, \"pathfinder_iterations_tests.csv\"), delimiter=\";\")\n",
    "df_iter_filt = df_iter[(df_iter[\"iter_success\"] == True) & (df_iter[\"tgt_zx_type\"] != \"O\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c08533",
   "metadata": {},
   "source": [
    "Now we can proceed to visualise the data and, in particular, the relation between:\n",
    "- Visitation attempts and runtimes: the algorithm only places a block if the coordinate/block combination clears a number of checks, so the purest reflection of the number of times the algorithm runs most of its operations is the number of times it \"visits\" a \"site\" and tries to place a block in it irrespective of whether the block is ultimately placed in the site or not.\n",
    "- Length of longest path in run and runtimes: the closest to a \"radius\" for the pathfinder algorithm is not the pure Manhattan distance between a source and a target but the length of the longest path generated in any given run of the algorithm, as this path subsumes the 4th (kind) dimension visited by the algorithm in the form of extra length relatively to a direct path between source and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62713cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SERIES, LABELS, & TITLES\n",
    "series = [\"num_visitation_attempts\", \"len_longest_path\"]\n",
    "x_labels = [\"No. of visitation attempts\", \"Le. of longest path\"]\n",
    "titles = [\"Duration v. Visitation attempts\", \"Duration v. Len. of longest path\"]\n",
    "\n",
    "# MATPLOTLIB VISUALISATION\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(series), figsize=(7 * len(series), 5))\n",
    "fig.suptitle(\"Pathfinder runtimes (single segments)\", fontsize=18)\n",
    "for i, series_name in enumerate(series):\n",
    "\n",
    "    axes[i].scatter(\n",
    "        df_iter_filt[series_name],\n",
    "        df_iter_filt[\"iter_duration\"],\n",
    "        marker=\"x\",\n",
    "        color=\"b\",\n",
    "        label=\"Individual durations\",\n",
    "    )\n",
    "\n",
    "    series_ave_dur = df_iter_filt.groupby(series_name)[\"iter_duration\"].mean()\n",
    "    axes[i].plot(\n",
    "        series_ave_dur.index,\n",
    "        series_ave_dur.values,\n",
    "        marker=\"o\",\n",
    "        linestyle=\"--\",\n",
    "        color=\"r\",\n",
    "        label=\"Average duration\",\n",
    "    )\n",
    "\n",
    "    min_x = int(df_iter_filt[series_name].min())\n",
    "    max_x = int(df_iter_filt[series_name].max())\n",
    "    axes[i].set_title(titles[i], fontsize=14)\n",
    "    axes[i].set_xlabel(x_labels[i], fontsize=10)\n",
    "    axes[i].set_ylabel(\"Average duration (seconds)\", fontsize=10)\n",
    "    axes[i].set_xticks(ticks=range(min_x, max_x + 1, max(1, int((max_x - min_x) / 10))))\n",
    "    axes[i].grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "    axes[i].legend()\n",
    "\n",
    "# GRAPH VISUAL ADJUSTMENTS\n",
    "plt.tight_layout()\n",
    "\n",
    "# SAVE PLOT TO FILE (Uncomment to save plot to file)\n",
    "# plt.savefig(\"pathfinder_duration_edges_from_full_circuit_runs\")\n",
    "\n",
    "# SHOW PLOT\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d370f9d",
   "metadata": {},
   "source": [
    "In all runs of this notebook we have done by ourselves, the charts above match expectations: \n",
    "- There is a clear linear relation between the number of sites visited and the runtimes, \n",
    "- There is a seemingly exponential relation between the the lenght of the longest path (the closest thing available to a \"radius\" for this algorithm, as it considers types by means of extra path lenght relative to a pure Manhattan distance) and runtimes.\n",
    "\n",
    "It can also be observed from the figures that iteration times tend to stick together, which sugggests runtimes will be homogeneous given homogeneous conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5c6f22",
   "metadata": {},
   "source": [
    "## 2. Assembling real circuits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb892aa",
   "metadata": {},
   "source": [
    "This section relies on the existence of data about regular runs of the full algorithmic cycle. Check the files `./assets/stats/pathfinder_iterations.csv` and `./assets/stats/bfs_manager.csv` to ensure you have data to work with.\n",
    "\n",
    "Topologiq *can* regularly log stats about the following aspects of any normal runs:\n",
    "- Metrics about the performance of the pathfinder algorithm, for each run of the pathfinder, \n",
    "- Metrics about the performance of the full algorithmic cycle, including runtimes for the full process and data about the original graphs and any outputs.\n",
    "\n",
    "The main runner function *can* receive an optional (boolean) parameter called `log_stats`. If `log_stats` is set to `True`, the graph manager will turn logging on pass a unique identifier around to ensure all logs can be connected.\n",
    "\n",
    "It is good practice to log stats from a few runs here and there, which should, overtime, produce a good sample reflecting varied usage conditions and circuits.\n",
    "\n",
    "***That said,*** if you have never run the algorithm with stats logs enabled and still want to run this notebook, you can append `--log_stats` to any of the examples in the [README](../../README.md), as well as `--repeat:50` so the example is run 50 times automatically. For a good sample, you will need to do this for several examples. Refer to the [README](../../README.md) for command examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dbaac0",
   "metadata": {},
   "source": [
    "### 2.1. Pathfinder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8a76f5",
   "metadata": {},
   "source": [
    "Let's start by repeating the previous analysis with data from real runs of the entire algorithmic process. \n",
    "\n",
    "The first step is, of course, loading the data about iterations by the core pathfinder algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c16e928",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iter_full_circuits = pd.read_csv(os.path.join(stats_dir, \"pathfinder_iterations.csv\"), delimiter=\";\")\n",
    "df_filt_full_circuits = df_iter_full_circuits[\n",
    "    (df_iter_full_circuits[\"iter_success\"] == True)\n",
    "    & (df_iter_full_circuits[\"tgt_zx_type\"] != \"O\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55474dc3",
   "metadata": {},
   "source": [
    "It is then possible to visualise this data similarly to how it was done with the data about single segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dab4934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SERIES, LABELS, & TITLES\n",
    "series = [\"num_visitation_attempts\", \"len_longest_path\"]\n",
    "x_labels = [\"No. of visitation attempts\", \"Le. of longest path\"]\n",
    "titles = [\"Duration v. Visitation attempts\", \"Duration. v. Len. of longest path\"]\n",
    "\n",
    "# MATPLOTLIB VISUALISATION\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(series), figsize=(7 * len(series), 5))\n",
    "fig.suptitle(\"Pathfinder runtimes (segments from full circuits)\", fontsize=18)\n",
    "for i, series_name in enumerate(series):\n",
    "\n",
    "    axes[i].scatter(\n",
    "        df_filt_full_circuits[series_name],\n",
    "        df_filt_full_circuits[\"iter_duration\"],\n",
    "        marker=\"x\",\n",
    "        color=\"b\",\n",
    "        label=\"Individual durations\",\n",
    "    )\n",
    "\n",
    "    series_ave_dur = df_filt_full_circuits.groupby(series_name)[\"iter_duration\"].mean()\n",
    "    axes[i].plot(\n",
    "        series_ave_dur.index,\n",
    "        series_ave_dur.values,\n",
    "        marker=\"o\",\n",
    "        linestyle=\"--\",\n",
    "        color=\"r\",\n",
    "        label=\"Average duration\",\n",
    "    )\n",
    "\n",
    "    min_x = int(df_filt_full_circuits[series_name].min())\n",
    "    max_x = int(df_filt_full_circuits[series_name].max())\n",
    "    axes[i].set_title(titles[i], fontsize=14)\n",
    "    axes[i].set_xlabel(x_labels[i], fontsize=10)\n",
    "    axes[i].set_ylabel(\"Duration (seconds)\", fontsize=10)\n",
    "    axes[i].set_xticks(ticks=range(min_x, max_x + 1, max(1, int((max_x - min_x) / 10))))\n",
    "    axes[i].grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "    axes[i].legend()\n",
    "\n",
    "# GRAPH VISUAL ADJUSTMENTS\n",
    "plt.tight_layout()\n",
    "\n",
    "# SAVE PLOT TO FILE (Uncomment to save plot to file)\n",
    "# plt.savefig(\"pathfinder_duration_edges_from_full_circuit_runs\")\n",
    "\n",
    "# SHOW PLOT\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c02a04",
   "metadata": {},
   "source": [
    "In all runs of this notebook we have done by ourselves, the charts above show more variability due to coming from runs of different circuits, but the fundamental patterns match expectations: \n",
    "- The relation between the number of sites visited and the runtimes remains linear, \n",
    "- The relation between the the lenght of the longest path and runtimes seems exponential."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdfed9f",
   "metadata": {},
   "source": [
    "### 2.2 Full cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e23ffb",
   "metadata": {},
   "source": [
    "When stats logging is enabled, ***topologiq*** will also save data about the full algorithmic cycle. Let's check runtimes for the entire process! \n",
    "\n",
    "Firstly, let's load the data.\n",
    "\n",
    "We will:\n",
    "- Filter it to, for now, to include only successful runs,\n",
    "- Add a column for the node-to-edge ratio of the incoming ZX circuit (numbers considerably below 1 indicate a dense graph with more edges than nodes),\n",
    "- Filter outliers by groups, to avoid biasing results with excessive delays in runtimes that do not reflect usual performance (typically caused by some sort of computer or user glitch such as, for instance, closing the computer while the process is running and having the process finish hours later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff21446",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cycle = pd.read_csv(os.path.join(stats_dir, \"graph_manager_cycle.csv\"), delimiter=\";\")\n",
    "df_cycle_filt = df_cycle[df_cycle[\"run_success\"] == True].copy()\n",
    "df_cycle_filt[\"node_edge_ratio\"] = np.where(df_cycle_filt[\"num_input_nodes_processed\"] != 0, df_cycle_filt[\"num_input_nodes_processed\"] / df_cycle_filt[\"num_input_edges_processed\"], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf9707f",
   "metadata": {},
   "source": [
    "In this case, we will visualise runtimes by several factors:\n",
    "- By the number of nodes in the original graph, which roughly shows the size of the original circuit\n",
    "- By the node-to-edge ratio in the original graph, which communicates the density of the original graph (ratios below 1: graph had more edges than nodes)\n",
    "- By the number of cubes in the final ouput, a proxy of how many operations the algorithm had to take to assemble the circuit.\n",
    "- By the name of the circuit, which aggregates performance over many runs of the same circuit.\n",
    "\n",
    "Please note that the numbers aggregate performance for often-very-different versions of the same circuit. The best performing runs for any given circuit can be as much as twice as fast as the worst performing runs. This is non-ideal, but it reflects the current state of affairs: ***topologiq*** does not currenlty have a mechanism to ensure the best performing version of a circuit is always returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd0db5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION TO REMOVE OUTLIERS BY GROUPS\n",
    "def remove_outliers(df, series_name):\n",
    "    q1 = df.groupby(series_name)[\"duration_total\"].transform(\"quantile\", 0.05)\n",
    "    q3 = df.groupby(series_name)[\"duration_total\"].transform(\"quantile\", 0.95)\n",
    "    iqr = q3 - q1\n",
    "\n",
    "    low = q1 - 1.5 * iqr\n",
    "    up = q3 + 1.5 * iqr\n",
    "\n",
    "    df_clean = df[\n",
    "        (df[\"duration_total\"] >= low)\n",
    "        & (df[\"duration_total\"] <= up)\n",
    "    ]\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "\n",
    "# SERIES, LABELS, & TITLES\n",
    "series = [[\"num_input_nodes_processed\", \"node_edge_ratio\"], [\"num_blocks_output\", \"circuit_name\"]]\n",
    "x_labels = [\n",
    "    [\"No. nodes/spiders (input)\", \"Node/edge ratio (input)\"],\n",
    "    [\"Num. blocks (output)\", \"Name of circuit\"],\n",
    "]\n",
    "titles = [\n",
    "    [\n",
    "        \"Duration v. Num nodes in input graph\",\n",
    "        \"Duration v. Nodes-to-edge ration of input graph\",\n",
    "    ],\n",
    "    [\"Duration v. Num blocks in output\", \"Duration v. Name of circuit\"],\n",
    "]\n",
    "\n",
    "# MATPLOTLIB VISUALISATION\n",
    "fig, axes = plt.subplots(nrows=2, ncols=len(series), figsize=(7 * len(series), 6))\n",
    "fig.suptitle(\"Pathfinder runtimes (segments from full circuits)\", fontsize=18)\n",
    "\n",
    "for i, row in enumerate(series):\n",
    "    \n",
    "    for j, series_name in enumerate(row):\n",
    "        \n",
    "        df_cycle_filt_clean = remove_outliers(df_cycle_filt, series_name)\n",
    "        \n",
    "        if i != 1 or j != 1: \n",
    "            axes[i][j].scatter(\n",
    "                df_cycle_filt_clean[series_name],\n",
    "                df_cycle_filt_clean[\"duration_total\"],\n",
    "                marker=\"x\",\n",
    "                color=\"b\",\n",
    "                label=\"Individual durations\",\n",
    "            )\n",
    "\n",
    "            series_ave_dur = df_cycle_filt_clean.groupby(series_name)[\n",
    "                \"duration_total\"\n",
    "            ].mean()\n",
    "            axes[i][j].plot(\n",
    "                series_ave_dur.index,\n",
    "                series_ave_dur.values,\n",
    "                marker=\"o\",\n",
    "                linestyle=\"--\",\n",
    "                color=\"r\",\n",
    "                label=\"Average duration\",\n",
    "            )\n",
    "            \n",
    "            axes[i][j].set_title(titles[i][j], fontsize=10)\n",
    "            axes[i][j].set_xlabel(x_labels[i][j])\n",
    "            axes[i][j].set_ylabel(\"Duration (seconds)\") \n",
    "\n",
    "        else:\n",
    "            axes[i][j].scatter(\n",
    "                df_cycle_filt_clean[\"duration_total\"],\n",
    "                df_cycle_filt_clean[series_name],\n",
    "                marker=\"x\",\n",
    "                color=\"b\",\n",
    "                label=\"Individual durations\",\n",
    "            )\n",
    "             \n",
    "            axes[i][j].set_title(titles[i][j], fontsize=14)\n",
    "            axes[i][j].set_xlabel(\"Duration (seconds)\", fontsize=10)\n",
    "            axes[i][j].set_ylabel(x_labels[i][j], fontsize=10) \n",
    "        \n",
    "       \n",
    "        axes[i][j].grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "\n",
    "# GRAPH VISUAL ADJUSTMENTS\n",
    "plt.tight_layout()\n",
    "\n",
    "# SAVE PLOT TO FILE (Uncomment to save plot to file)\n",
    "# plt.savefig(\"pathfinder_duration_edges_from_full_circuit_runs\")\n",
    "\n",
    "# SHOW PLOT\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa73949",
   "metadata": {},
   "source": [
    "At the moment, the only thing that can be inferred from the above with some degree of certainty is that there is significantly variability of runtimes across circuits of different kinds to enable hard conclusions from any of the above. \n",
    "\n",
    "There is a slight upwards trend in the relation between number of nodes in input and output and the runtimes. This makes sense. The more nodes and edges in the incoming ZX graph, the more nodes and edges there are for processing. However, some of the runs of circuits with 16 nodes stop the clock at around similar times as circuits with 10 nodes. This might suggest runtimes are informed partially by the size of the incoming and by extension outgoing graph, but that other factors also matter. \n",
    "\n",
    "Additional research is needed to determine the additional factors that influence times.\n",
    "\n",
    "Preliminarily, it might be worth to look into the reasons for the variability related to the node-to-edge ratios and the different circuits (especially the \"simple mess\", which has quite a broad range of possible runtime values)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
